<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Matching</title>
    <script defer src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.min.js"></script>
    <style>
        body { text-align: center; font-family: Arial, sans-serif; }
        #video { width: 400px; height: 300px; border: 2px solid black; }
        #overlay { position: absolute; top: 0; left: 0; }
    </style>
</head>
<body>

    <h2>Face Recognition</h2>
    <video id="video" autoplay></video>
    <canvas id="overlay"></canvas>
    <br>
    <input type="file" id="imageUpload" accept="image/*">
    <p id="info">Upload an image to start matching.</p>

    <script>
        let referenceDescriptors = [];
        let faceMatcher = null;

        async function loadModels() {
            const MODEL_URL = 'https://justadudewhohacks.github.io/face-api.js/models/';
            await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
            await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
            await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);
            console.log('‚úÖ Models Loaded');
        }

        async function startCamera() {
            const video = document.getElementById('video');
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
                video.srcObject = stream;
                await new Promise(resolve => video.onloadedmetadata = resolve);
                console.log('‚úÖ Camera started');
            } catch (error) {
                console.error('‚ùå Error starting camera:', error);
            }
        }

        async function detectFace() {
            const video = document.getElementById('video');
            await video.play();

            const canvas = document.getElementById('overlay');
            const ctx = canvas.getContext('2d');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            faceapi.matchDimensions(canvas, { width: video.videoWidth, height: video.videoHeight });

            setInterval(async () => {
                const detections = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
                    .withFaceLandmarks()
                    .withFaceDescriptor();

                ctx.clearRect(0, 0, canvas.width, canvas.height);

                if (detections) {
                    console.log('‚úÖ Face detected:', detections);

                    faceapi.draw.drawDetections(canvas, faceapi.resizeResults([detections], { width: video.videoWidth, height: video.videoHeight }));
                    faceapi.draw.drawFaceLandmarks(canvas, faceapi.resizeResults([detections], { width: video.videoWidth, height: video.videoHeight }));

                    let matchText = "No match detected";

                    if (faceMatcher && referenceDescriptors.length > 0) {
                        const bestMatch = faceMatcher.findBestMatch(detections.descriptor);
                        const distance = bestMatch.distance; // 0 = perfect match, 1 = no match

                        let matchPercentage = ((1 - distance) * 100).toFixed(2); // Convert distance to percentage
                        matchPercentage = Math.max(matchPercentage, 0); // Ensure it's not negative

                        console.log(`üéØ Match Found: ${matchPercentage}%`);
                        matchText = `Match: ${matchPercentage}%`;
                    }

                    ctx.font = "20px Arial";
                    ctx.fillStyle = "red";
                    ctx.fillText(matchText, 20, 30);
                } else {
                    console.log("‚ùå No face detected in video frame.");
                }
            }, 500);
        }

        document.getElementById('imageUpload').addEventListener('change', async function(event) {
            const imageFile = event.target.files[0];
            if (!imageFile) return;

            console.log('üìÇ Image uploaded:', imageFile.name);

            const img = await faceapi.bufferToImage(imageFile);
            document.body.appendChild(img); // Show image for debugging

            setTimeout(async () => {
                const detections = await faceapi.detectSingleFace(img, new faceapi.TinyFaceDetectorOptions())
                    .withFaceLandmarks()
                    .withFaceDescriptor();

                if (detections) {
                    referenceDescriptors.push(detections.descriptor);
                    faceMatcher = new faceapi.FaceMatcher(
                        new faceapi.LabeledFaceDescriptors("Uploaded Face", referenceDescriptors)
                    );

                    console.log("‚úÖ Face descriptor extracted from image:", referenceDescriptors);
                    document.getElementById('info').innerText = "‚úÖ Image uploaded! Now match with live face.";

                    img.remove(); // Remove image after detection
                } else {
                    document.getElementById('info').innerText = "‚ùå No face found in uploaded image!";
                    console.log("‚ùå No face detected in uploaded image.");
                }
            }, 1000);
        });

        async function init() {
            console.log("üöÄ Initializing...");
            await loadModels();
            await startCamera();
            detectFace();
        }

        window.onload = init;
    </script>
</body>
</html>
